---
layout: post
title:  "CVPR2018 Summary"
date:   2018-12-21
excerpt: "Just about everything you'll need to style in the theme: headings, paragraphs, blockquotes, tables, code blocks, and more."
tag:
- CVPR2018 
- GAN
- Face Detection
comments: true
---

## Finding Tiny Faces in the Wild with Generative Adversarial Network[^1]

该论文提出的方法主要解决的问题是图像中小人脸的检测问题。针对检测模型提取出的Proposal，该论文基于 GAN 的方法将其中分辨率小且模糊的人脸进行超分辨率及清晰化处理。

### 方法

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="http://cuijyer-images.oss-cn-beijing.aliyuncs.com/20181221_cvpr2018_summary_1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">论文提出的模型流程图：(A) 送入网络的输入图像；(B)  MB-FCN 检测器，可裁切出输入图像中的人脸区域（正例图像）和非人脸区域（反例图像），这些数据用来送入后面的生成器和判别器用于模型训练；(C) 使用 MB-FCN 检测器生成的人脸区域数据（正例图像）和非人脸区域数据（反例图像）；(D) 提出的生成器网络结构，用于从一个低分辨率的图像重构出一个清晰的超分辨率图像（分辨率提高4倍），生成器网络包括上采样子网络和精调子网络；(D) 使用 VGG19 结构作为判别器，后面接有两个并行的 FC 层，分别用来判别输入的数据是否是真实的超分辨率图像和是否是人脸区域。</div>
</center>

#### GAN

常规的 GAN 的目标函数定义如下：

$$ \mathcal{L}_{GAN}(G, D) = \mathbb{E}_{x\sim p_{data}(x)}[log D_{\theta}(x)] + \mathbb{E}_{z\sim p_{z}(z)}[log(1 - D_{\theta}(G_{\omega}(z)))] $$

其中，$$z$$ 表示随机噪声，$$x$$ 是真实的数据，$$\theta$$ 和 $$\omega$$ 分别是生成器 $$G$$ 和判别器 $$D$$ 的参数。模型优化的目标如下：

$$ \arg \min_{G}\max_{D} \mathcal{L}_{GAN}(G, D) $$

和常规的 GAN 的类似，除了输入的不是随机噪声，而是正例和反例图像，目标函数和优化目标如下：

$$ \arg \min_{\omega_{G}}\max_{\theta_{D}} \mathbb{E}_{(I^{HR},y)\sim p^{train}(I^{HR}, y)}[\log D_{\theta_{D}}(I^{HR}, y)] + \\
\mathbb{E}_{(I^{LR},y)\sim p^{G}(I^{LR}, y)}[\log (1 - D_{\theta_{D}}(G_{\omega_{G}}(I^{HR}, y)))] $$

其中，$$I^{LR}$$ 表示的是低分辨率的图像，$$I^{HR}$$ 是高分辨率的图像，$$y$$ 是输入图像的标签。在判别网络，判别器不仅要判别生成图像的高分辨率图像和真实的高分辨率图像，还要判别人脸图像和非人脸图像。

#### 损失函数

论文中采用了两种损失函数，分别是 pixel-wise loss 和 adversarial loss。


**pixel-wise loss.** 通过引入 pixel-wise MSE loss，可以让生成器生成的高分辨率图像和真实高分辨率图像在纹理信息上接近。损失函数如下：

$$ L_{MSE}(\omega) = \frac{1}{N} \sum_{i=1}^{N}(\| G_{1_{\omega 1}}(I_{i}^{LR}) - I_{i}^{HR} \|^{2} + \| G_{2_{\omega 2}}(G_{1_{\omega 1}}(I_{i}^{LR}) - I_{i}^{HR} \|^{2}) $$

其中，$$ I^{LR} $$ 和 $$ I^{HR} $$ 分别表示低分辨率模糊图像和高分辨率图像，$$ G_{1} $$ 代表了生成器网络中的上采样子网络，而 $$G_{2}$$ 代表了生成器网络中的精调子网络，$$\omega$$ 是生成器的参数。但 MSE 优化问题总是会丢失图像的高频信息，造成生成的图像偏向于模糊或者过平滑。

**Adversarial loss.** 为了得到更加真实清晰的细节信息，作者引入了 adversarial loss，定义如下：

$$ L_{adv} = \frac{1}{N}\sum_{i=1}^{N}\log (1 - D_{\theta}(G_{\omega}(I_{i}^{LR}))) $$

引入的 adversarial loss 使得生成器生成出来的图像更加的清晰，包含有更多的高频信息以可以欺骗判别器模型。

**Classification loss.** 训练数据除了有低分辨率和高分辨率之分，还有人脸和非人脸的差异，由此引入了 classification loss，用来判别是否是人脸图像。损失函数定义如下：

$$ L_{cls} = \frac{1}{N}\sum_{i=1}^{N}(\log (y_{i} - D_{\theta}(G_{\omega}(I_{i}^{LR}))) + \log (y_{i} - D_{\theta}(I_{i}^{HR}))) $$

其中 $$y_{i}$$ 是图像是否是人脸图像的标签，$$y_{i}=1$$ 表示图像是人脸图像，$$y_{i}=0$$ 表示的是非人脸图像。

**Objective funciton.** 目标函数是上述三个损失函数的加权求和：

$$ \max_{\theta}\min_{\omega} \frac{1}{N}\sum_{i=1}^{N}\alpha(\log (1 - D_{\theta}(G_{\omega}(I_{i}^{LR})) +  \log D_{\theta}(I_{i}^{HR})) + \\ 
(\| G_{1_{\omega 1}}(I_{i}^{LR}) - I_{i}^{HR} \|^{2} + \| G_{2_{\omega 2}}(G_{1_{\omega 1}}(I_{i}^{LR}) - I_{i}^{HR} \|^{2}) + \\ 
\beta(\log (y_{i} - D_{\theta}(G_{\omega}(I_{i}^{LR}))) + \log (y_{i} - D_{\theta}(I_{i}^{HR})))$$

其中，$$\alpha$$ 和 $$\beta$$ 分别代表权重。

### 消融实验

实验用的数据集是 WIDER FACE dataset，总共包含 32,203 张密集的人脸图像，其中按照人脸的大小，分为简单/中等/难三个子数据集。论文中作者做了消融实验来验证提出的一系列损失函数的有效性，如下图所示：
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="http://cuijyer-images.oss-cn-beijing.aliyuncs.com/20181221_cvpr2018_summary_2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">消融实验：Baseline 方法和分别加入精调网络、对抗损失、分类损失和论文提出的方法在 WIDER FACE dataset 上的表现。</div>
</center>


[^1]: Y.C. Bai, Y.Q. Zhang, M.L. Ding and B. Ghanem, Finding Tiny Faces in the Wild with Generative Adversarial Network, In Proc. CVPR, 2018.